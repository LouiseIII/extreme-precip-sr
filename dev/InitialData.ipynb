{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import random\n",
    "\n",
    "from datetime import timedelta, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINITION OF THE DOMAIN OF INTEREST \n",
    "\n",
    "lat_bnd = [-1.2, 0.94]\n",
    "lon_bnd = [-2.84, 0.02]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generating High-Resolution Data \n",
    "\n",
    "**DATA :** Sourced from _'data/HadGEM_driven_COSMO'_\n",
    "\n",
    "**OBJECTIVE :** In this section, independent monthly hourly precipitation maxima will be extracted. This corresponds to the highest hourly precipitation recorded during a summer month (June, July, August). To ensure event independence, all maxima must be spaced at least five days apart. This will be done for the two 11-year periods : \n",
    "- _Present_ : between 1999 and 2009.\n",
    "- _Future_ : between 2079 and 2089. \n",
    "\n",
    "**PROCESS :** This is done in three phases:\n",
    "\n",
    "- **Extraction of initial Maximum** -- Generate the maximum precipitation per month along with the associated timestamp.\n",
    "- **Conflict Resolution** -- Ensure that all maxima are spaced by at least 5 days. If not:\n",
    "    - Retain the event with the highest precipitation value.\n",
    "    - Define upper and lower time constraints for the discarded event.\n",
    "- **Adjusted Maximum Calculation** -- Recalculate the maximum for cases that need to be adjusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Extraction of initial Maximum\n",
    "\n",
    "**OUTPUT :** \n",
    "- The data is stored in  _'repos/Downscaling_CM/data/data_high_resolution'_ \n",
    "- Format: _data2_summer_present_HR_v0.csv_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERIOD = 'Present/'\n",
    "\n",
    "if PERIOD == 'Present/': year_min, year_max = 1999, 2010\n",
    "elif PERIOD == 'Future/' : year_min, year_max = 1999, 2010\n",
    "else : print('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_month_HR (name, year, period = 'Present/'):\n",
    "\n",
    "    '''\n",
    "    Input: Beginning of the filename for a specific month and year + target year + period ('Present' or 'Future')  \n",
    "    Output: Dataset containing, for each location in the study domain (rlat / rlon), the maximum hourly precipitation, along with the corresponding year and month.  \n",
    "    '''\n",
    "\n",
    "    os.chdir(\"/data/HadGEM_driven_COSMO/\"+period+str(year))\n",
    "    fichiers_month = [fichier for fichier in os.listdir() if fichier.startswith(name)]\n",
    "    liste_data = []\n",
    "\n",
    "    for ind in range(len(fichiers_month)) :\n",
    "        \n",
    "        data=xr.open_dataset(fichiers_month[ind])\n",
    "        \n",
    "        data = data.sel(rlon = slice(*lon_bnd), rlat = slice(*lat_bnd))\n",
    "        vars_to_keep = ['TOT_PR', 'rlat', 'rlon', 'time']  \n",
    "        data = data.drop_vars([var for var in data.variables if var not in vars_to_keep])\n",
    "        data = data.to_dataframe()\n",
    "        data= data.reset_index()\n",
    "\n",
    "        data.rlat = round(data.rlat, 2)\n",
    "        data.rlon = round(data.rlon, 2)\n",
    "\n",
    "        liste_data.append(data)\n",
    "\n",
    "    liste_data = pd.concat(liste_data, ignore_index = True)\n",
    "\n",
    "    ind = liste_data.groupby(['rlat', 'rlon'])['TOT_PR'].idxmax()\n",
    "    liste_data = liste_data.loc[ind]\n",
    "\n",
    "    liste_data['year'] = year\n",
    "    liste_data['month'] = name[8:10]\n",
    "    liste_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return liste_data\n",
    "\n",
    "liste_data = [get_max_month_HR(f\"lffd{year}{mois}\", year, PERIOD) for year in range(year_min, year_max) for mois in ['06', '07', '08']]\n",
    "liste_data = pd.concat(liste_data, ignore_index = True)\n",
    "\n",
    "os.chdir(\"/data/data_high_resolution\")\n",
    "liste_data.to_csv('data2_summer_present_HR_v0.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Conflict Resolution\n",
    "\n",
    "To ensure the independence of events, we will check whether each event is spaced at least 5 days apart. If not:  \n",
    "- The highest precipitation value is retained.  \n",
    "- Lower and upper time constraint values are recorded.  \n",
    "\n",
    "The values are then organized into three datasets:  \n",
    "1) **data_clean** → Events without conflicts.  \n",
    "2) **data_conflict** → Events that require recalculation.  \n",
    "3) **data_corrected** → Corrected data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If not in memory \n",
    "os.chdir('/data/data_high_resolution')\n",
    "liste_data = pd.read_csv('data2_summer_present_HR_v0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_conflit (liste_data):\n",
    "\n",
    "    liste_data['time'] = pd.to_datetime(liste_data['time'])\n",
    "    liste_data['to_change'] = 0 # (0 if there is no conflit, 1 otherwise)\n",
    "    liste_data['constraint_begin'] = None \n",
    "    liste_data['constraint_end'] = None\n",
    "\n",
    "    for (rlat, rlon, year), df in tqdm.tqdm(liste_data.groupby(['rlat', 'rlon', 'year'], group_keys=False)):\n",
    "        df = df.sort_values(by='time').reset_index()\n",
    "\n",
    "        for i in range(len(df) - 1):\n",
    "            time_i = df.loc[i, 'time']\n",
    "            time_j = df.loc[i + 1, 'time']\n",
    "\n",
    "            if abs((time_j - time_i).days) < 5:\n",
    "\n",
    "                if df.loc[i, 'TOT_PR'] < df.loc[i + 1, 'TOT_PR']:\n",
    "                    index_to_change = df.loc[i, 'index']\n",
    "                    time_to_change = df.loc[i, 'time']\n",
    "                    other_time = df.loc[i + 1, 'time']\n",
    "                else:\n",
    "                    other_time = df.loc[i, 'time']\n",
    "                    index_to_change = df.loc[i + 1, 'index']\n",
    "                    time_to_change = df.loc[i + 1, 'time']\n",
    "\n",
    "                liste_data.loc[index_to_change, 'to_change'] = 1 \n",
    "\n",
    "                month = time_to_change.month\n",
    "\n",
    "                if month == 6: \n",
    "                    liste_data.loc[index_to_change, 'constraint_begin'] = f\"{time_to_change.year}-05-31\"\n",
    "                    liste_data.loc[index_to_change, 'constraint_end'] = other_time - pd.Timedelta(days=5)\n",
    "\n",
    "                elif month == 8:\n",
    "                    liste_data.loc[index_to_change, 'constraint_begin'] = other_time + pd.Timedelta(days=5)\n",
    "                    liste_data.loc[index_to_change, 'constraint_end'] = f\"{time_to_change.year}-09-01\"\n",
    "\n",
    "                elif month == 7:  \n",
    "                    june_max = df[df['time'].dt.month == 6]['time'].max()\n",
    "                    august_max = df[df['time'].dt.month == 8]['time'].min()\n",
    "\n",
    "                    liste_data.loc[index_to_change, 'constraint_begin'] = june_max + pd.Timedelta(days=5)\n",
    "                    liste_data.loc[index_to_change, 'constraint_end'] = august_max - pd.Timedelta(days=5)\n",
    "\n",
    "    return liste_data\n",
    "\n",
    "liste_data = detect_conflit(liste_data)\n",
    "data_conflict = liste_data.loc[liste_data.to_change == 1].copy()\n",
    "data_clean = liste_data.loc[liste_data.to_change == 0].copy()\n",
    "if len(liste_data) != len(data_clean) + len(data_conflict) : print('-ERROR-')\n",
    "print('There is ', len(data_conflict), ' conflicts (', np.round(len(data_conflict)/len(liste_data)*100), '%).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example : analyse d'un conflit\n",
    "indice = random.choice(data_conflict.index)\n",
    "year = data_conflict.year[indice]\n",
    "rlat = data_conflict.rlat[indice]\n",
    "rlon = data_conflict.rlon[indice]\n",
    "\n",
    "df_local = liste_data.loc[(liste_data.year == year) &\n",
    "                          (liste_data.rlat == rlat) &\n",
    "                          (liste_data.rlon == rlon)]\n",
    "df_local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Adjusted Maximum Calculation\n",
    "\n",
    "**OUTPUT :** \n",
    "- The data is stored in  _'/data/data_high_resolution'_ \n",
    "- Format: _data2_summer_present_HR_v1.csv_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corrected = []\n",
    "PERIOD = 'Present/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_month_HR_with_constraints (name, year, period, constraint_begin, constraint_end, lat_bnd, lon_bnd):\n",
    "\n",
    "    os.chdir(\"/data/HadGEM_driven_COSMO/\"+period+str(year))\n",
    "    fichiers_month = [fichier for fichier in os.listdir() if fichier.startswith(name)]\n",
    "    liste_data = []\n",
    "\n",
    "    for ind in range(len(fichiers_month)) :\n",
    "        \n",
    "        data=xr.open_dataset(fichiers_month[ind])\n",
    "        \n",
    "        data = data.sel(rlon = slice(*lon_bnd), rlat = slice(*lat_bnd))\n",
    "        vars_to_keep = [\"TOT_PR\", 'rlat', 'rlon', 'time']  \n",
    "        data = data.drop_vars([var for var in data.variables if var not in vars_to_keep])\n",
    "        data = data.to_dataframe()\n",
    "        data= data.reset_index()\n",
    "        data = data.loc[(data.time >= constraint_begin) & (data.time <= constraint_end)]\n",
    "        \n",
    "        data.rlat = round(data.rlat, 2)\n",
    "        data.rlon = round(data.rlon, 2)\n",
    "\n",
    "        liste_data.append(data)\n",
    "\n",
    "    liste_data = pd.concat(liste_data, ignore_index = True)\n",
    "\n",
    "    ind = liste_data.groupby(['rlat', 'rlon'])['TOT_PR'].idxmax()\n",
    "    liste_data = liste_data.loc[ind]\n",
    "\n",
    "    liste_data['year'] = year\n",
    "    liste_data['month'] = name[8:10]\n",
    "    liste_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return liste_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_conflict[['constraint_end', 'constraint_begin']] = data_conflict[['constraint_end', 'constraint_begin']].apply(pd.to_datetime)\n",
    "\n",
    "for year in range(1999, 2010):\n",
    "    for month in [6, 7, 8]:\n",
    "\n",
    "        # Initialisation \n",
    "        mois = f\"{month:02d}\"\n",
    "        name = f\"lffd{year}{mois}\"\n",
    "        \n",
    "        df_local = data_conflict.loc[(data_conflict.year == year) & ((data_conflict.month == month))].copy()\n",
    "\n",
    "        if month == 7:\n",
    "            month_conditions = [\n",
    "                (df_local.constraint_end.dt.month == 7) & (df_local.constraint_begin.dt.month == 7),\n",
    "                (df_local.constraint_end.dt.month == 7) & (df_local.constraint_begin.dt.month == 6),\n",
    "                (df_local.constraint_end.dt.month == 8) & (df_local.constraint_begin.dt.month == 7)\n",
    "            ]\n",
    "        else:\n",
    "            month_conditions = [df_local.index]  # Condition unique pour juin et août\n",
    "        \n",
    "        ### \n",
    "        for condition in month_conditions:\n",
    "            df_sub = df_local.loc[condition]\n",
    "\n",
    "            ind_prev = -1\n",
    "            \n",
    "            # Check groupé \n",
    "            while len(df_sub) > 0 and len(df_sub) != ind_prev:\n",
    "                ind_prev = len(df_sub)\n",
    "\n",
    "                lat_bnd = [df_sub.rlat.min(), df_sub.rlat.max()]\n",
    "                lon_bnd = [df_sub.rlon.min(), df_sub.rlon.max()]\n",
    "\n",
    "                df_result = get_max_month_HR_with_constraints(\n",
    "                    name, year, PERIOD, df_sub.constraint_begin.min(),\n",
    "                    df_sub.constraint_end.max(), lat_bnd, lon_bnd)\n",
    "                df_sub.drop(columns=['TOT_PR', 'time'], inplace = True)\n",
    "\n",
    "                for df in [df_sub, df_result]:\n",
    "                    df[['rlat', 'rlon']] = df[['rlat', 'rlon']].round(2).astype('float')\n",
    "\n",
    "                df_merge = pd.merge(df_sub, df_result[['rlat', 'rlon', 'TOT_PR', 'time']], on=['rlat', 'rlon'], how='left')\n",
    "\n",
    "                # Update \n",
    "                data_corrected.append(df_merge.loc[\n",
    "                    (df_merge.constraint_begin <= df_merge.time) &\n",
    "                    (df_merge.constraint_end >= df_merge.time)])\n",
    "                \n",
    "                df_sub = df_merge.loc[\n",
    "                    (df_merge.constraint_begin > df_merge.time) |\n",
    "                    (df_merge.constraint_end < df_merge.time)]\n",
    "                \n",
    "\n",
    "            # Check individuel \n",
    "            for _, df_remain in df_sub.iterrows():\n",
    "                df_remain = df_remain.to_frame().T \n",
    "\n",
    "                lat_bnd = [df_remain.rlat.min(), df_remain.rlat.max()]\n",
    "                lon_bnd = [df_remain.rlon.min(), df_remain.rlon.max()]\n",
    "\n",
    "                df_result = get_max_month_HR_with_constraints(\n",
    "                    name, year, PERIOD, df_remain.constraint_begin.min(),\n",
    "                    df_remain.constraint_end.max(), lat_bnd, lon_bnd\n",
    "                )\n",
    "\n",
    "                df_remain[['rlat', 'rlon']] = df_remain[['rlat', 'rlon']].round(2).astype('float64')\n",
    "                df_result[['rlat', 'rlon']] = df_result[['rlat', 'rlon']].round(2).astype('float64')\n",
    "\n",
    "                df_merge = df_remain.drop(columns=['TOT_PR', 'time']).merge(\n",
    "                    df_result[['rlat', 'rlon', 'TOT_PR', 'time']], on=['rlat', 'rlon'], how='left'\n",
    "                )\n",
    "\n",
    "                data_corrected.append(df_merge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part1 = liste_data.loc[liste_data.to_change == 1].copy()\n",
    "df_part2 = pd.concat(data_corrected)\n",
    "df_result = pd.concat([df_part1, df_part2])\n",
    "df.result.to_csv('data2_summer_present_HR_v1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generating Low-Resolution Data \n",
    "\n",
    "**DATA :** Sourced from _'downscaling/HadGEM_driven_COSMO'_\n",
    "\n",
    "**OBJECTIVE :** In this section, low-resolution data will be generated from the same dataset to establish an ideal framework. Then independent monthly hourly precipitation maxima will be extracted. This corresponds to the highest hourly precipitation recorded during a summer month (June, July, August). To ensure event independence, all maxima must be spaced at least five days apart. This will be done for the two 11-year periods : \n",
    "- _Present_ : between 1999 and 2009.\n",
    "- _Future_ : between 2079 and 2089. \n",
    "\n",
    "**PROCESS :** This is done in five phases:\n",
    "\n",
    "- **Create the grille** -- \n",
    "- **Data Blurring** -- Apply mean pooling to the data to reach the desired resolution. \n",
    "- **Extraction of initial Maximum** -- Generate the maximum precipitation per month along with the associated timestamp.\n",
    "- **Conflict Resolution** -- Ensure that all maxima are spaced by at least 5 days. If not:\n",
    "    - Retain the event with the highest precipitation value.\n",
    "    - Define upper and lower time constraints for the discarded event.\n",
    "- **Adjusted Maximum Calculation** -- Recalculate the maximum for cases that need to be adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERIOD = 'Present/'\n",
    "\n",
    "if PERIOD == 'Present/':\n",
    "    year_min, year_max = 1999, 2010\n",
    "    period_text = 'present'\n",
    "elif PERIOD == 'Future/' :\n",
    "    year_min, year_max = 1999, 2010\n",
    "    period_text = 'future'\n",
    "else : print('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Create the grille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = int(RESOLUTION / 2)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Intersection points at 2 km resolution\n",
    "liste_lat_2 = np.arange(lat_bnd[0], lat_bnd[1]+0.01, 0.02)\n",
    "liste_lon_2 = np.arange(lon_bnd[0], lon_bnd[1]+0.01, 0.02)\n",
    "\n",
    "# Intersection points at 12 km resolution\n",
    "liste_lat_12 = liste_lat_2[::resolution]\n",
    "liste_lon_12 = liste_lon_2[::resolution]\n",
    "\n",
    "# Ensure coverage by appending an extra point\n",
    "liste_lat_12 = np.append(liste_lat_12, np.max(liste_lat_2) + 0.01)\n",
    "liste_lon_12 = np.append(liste_lon_12, np.max(liste_lon_2) + 0.01)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Create the coordinate DataFrame\n",
    "lat_indices = np.arange(len(liste_lat_2))\n",
    "lon_indices = np.arange(len(liste_lon_2))\n",
    "lat_grid, lon_grid = np.meshgrid(lat_indices, lon_indices)\n",
    "\n",
    "dico_coord = pd.DataFrame({'rlat': np.array(liste_lat_2)[lat_grid.ravel()], \n",
    "                            'rlon': np.array(liste_lon_2)[lon_grid.ravel()]})\n",
    "\n",
    "# Assign a block number for each coordinate\n",
    "dico_coord['block'] = 'X'\n",
    "\n",
    "ind_block = 0\n",
    "for lat in liste_lat_12:\n",
    "    for lon in liste_lon_12:\n",
    "        mask = ((dico_coord.rlat < lat) & (dico_coord.rlon < lon) & (dico_coord.block == 'X'))\n",
    "        if mask.any():\n",
    "            dico_coord.loc[mask, 'block'] = ind_block\n",
    "            ind_block += 1\n",
    "\n",
    "# --------------------------------------------------------------------------- \n",
    "\n",
    "# Summarize data per block\n",
    "data_block = dico_coord.groupby('block').agg({'rlat': 'mean', 'rlon': 'mean'}).reset_index()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Find the nearest blocks for each position\n",
    "def find_min (lat, lon, df):\n",
    "    \n",
    "    distance = np.sqrt((df.rlat - lat)**2 + (df.rlon - lon)**2)\n",
    "    min_distance_index = distance.idxmin()\n",
    "    \n",
    "    block = df.loc[min_distance_index, 'block']\n",
    "\n",
    "    df = df.loc[df['block'] != block]\n",
    "    \n",
    "    return block, df\n",
    "\n",
    "# Initialize columns for neighbors\n",
    "dico_coord[['block1', 'block2']] = 'X', 'X'\n",
    "\n",
    "for ind in tqdm.tqdm(range(len(dico_coord))):\n",
    "    lon = dico_coord.rlon[ind]\n",
    "    lat = dico_coord.rlat[ind]\n",
    "    block = dico_coord.block[ind]\n",
    "\n",
    "    df = data_block.loc[data_block.block != block].copy()\n",
    "\n",
    "    block2, df = find_min(lat, lon, df)\n",
    "\n",
    "    dico_coord.loc[(dico_coord.rlat == lat) & (dico_coord.rlon == lon), ['block1', 'block2']] = [block, block2]\n",
    "   \n",
    "dico_coord.rlat = round(dico_coord.rlat, 2)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "dico_coord.to_csv('grille2_'+str(RESOLUTION)+'.csv', index=False)\n",
    "\n",
    "# Extracting simplified grid for further use\n",
    "grille = dico_coord[['rlat', 'rlon', 'block']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grille = grille.loc[grille.rlon >-0.5]\n",
    "grille = grille.loc[grille.rlat >0.5]\n",
    "\n",
    "# Assign a unique color for each block\n",
    "groups = grille.groupby('block')\n",
    "colors = plt.cm.get_cmap('tab20', len(groups))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i, (block, group) in enumerate(groups):\n",
    "    plt.scatter(group.rlon, group.rlat, color=colors(i), label=f'Block {block}', s=100)\n",
    "\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Scatter plot of grid points colored by block')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. & 2.2. Data Blurring & Extraction of initial Maximum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_month_LR (name, year, period = 'Present/'):\n",
    "\n",
    "    '''\n",
    "    Input: Beginning of the filename for a specific month and year + target year + period ('Present' or 'Future')  \n",
    "    Output: Dataset containing, for each block in the study domain (rlat / rlon), the maximum hourly precipitation, along with the corresponding year and month.  \n",
    "    '''\n",
    "\n",
    "    os.chdir(\"/downscaling/HadGEM_driven_COSMO/\"+period+str(year))\n",
    "    fichiers_month = [fichier for fichier in os.listdir() if fichier.startswith(name)]\n",
    "    liste_data = []\n",
    "\n",
    "    for ind in range(len(fichiers_month)) :\n",
    "\n",
    "        data=xr.open_dataset(fichiers_month[ind])\n",
    "        \n",
    "        data = data.sel(rlon = slice(*lon_bnd), rlat = slice(*lat_bnd))\n",
    "        vars_to_keep = ['rlat', 'rlon', 'TOT_PR', 'time']  \n",
    "        data = data.drop_vars([var for var in data.variables if var not in vars_to_keep])\n",
    "        data = data.to_dataframe()\n",
    "        data= data.reset_index()\n",
    "\n",
    "        data.rlat = round(data.rlat, 2)\n",
    "        data.rlon = round(data.rlon, 2)\n",
    "        data = pd.merge(data, grille, on = ['rlat', 'rlon'], how = 'left')\n",
    "        data_time = data.time[0]\n",
    "        data = data.groupby(['block'])['TOT_PR'].mean().reset_index()\n",
    "        data['time'] = data_time\n",
    "\n",
    "        liste_data.append(data)\n",
    "\n",
    "    liste_data = pd.concat(liste_data, ignore_index = True)\n",
    "    liste_data = liste_data.reset_index() \n",
    "    \n",
    "    ind = liste_data.groupby(['block'])['TOT_PR'].idxmax()\n",
    "    liste_data = liste_data.loc[ind]\n",
    "\n",
    "    liste_data['year'] = year\n",
    "    liste_data['month'] = name[8:10]\n",
    "\n",
    "    return liste_data \n",
    "\n",
    "liste_data = [get_max_month_HR(f\"lffd{year}{mois}\", year, PERIOD) for year in range(year_min, year_max) for mois in ['06', '07', '08']]\n",
    "liste_data = pd.concat(liste_data, ignore_index = True)\n",
    "\n",
    "os.chdir(\"/data/data_high_resolution\")\n",
    "liste_data.to_csv('data2_summer_'+period_text'_HR_v0.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Adjusted Maximum Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_conflit (liste_data):\n",
    "\n",
    "    liste_data['time'] = pd.to_datetime(liste_data['time'])\n",
    "    liste_data['to_change'] = 0 # (0 if there is no conflit, 1 otherwise)\n",
    "    liste_data['constraint_begin'] = None \n",
    "    liste_data['constraint_end'] = None\n",
    "\n",
    "    for (block, year), df in tqdm.tqdm(liste_data.groupby(['block', 'year'], group_keys=False)):\n",
    "        df = df.sort_values(by='time').reset_index()\n",
    "\n",
    "        for i in range(len(df) - 1):\n",
    "            time_i = df.loc[i, 'time']\n",
    "            time_j = df.loc[i + 1, 'time']\n",
    "\n",
    "            if abs((time_j - time_i).days) < 5:\n",
    "\n",
    "                if df.loc[i, 'TOT_PR'] < df.loc[i + 1, 'TOT_PR']:\n",
    "                    index_to_change = df.loc[i, 'index']\n",
    "                    time_to_change = df.loc[i, 'time']\n",
    "                    other_time = df.loc[i + 1, 'time']\n",
    "                else:\n",
    "                    other_time = df.loc[i, 'time']\n",
    "                    index_to_change = df.loc[i + 1, 'index']\n",
    "                    time_to_change = df.loc[i + 1, 'time']\n",
    "\n",
    "                liste_data.loc[index_to_change, 'to_change'] = 1 \n",
    "\n",
    "                month = time_to_change.month\n",
    "\n",
    "                if month == 6: \n",
    "                    liste_data.loc[index_to_change, 'constraint_begin'] = f\"{time_to_change.year}-05-31\"\n",
    "                    liste_data.loc[index_to_change, 'constraint_end'] = other_time - pd.Timedelta(days=5)\n",
    "\n",
    "                elif month == 8:\n",
    "                    liste_data.loc[index_to_change, 'constraint_begin'] = other_time + pd.Timedelta(days=5)\n",
    "                    liste_data.loc[index_to_change, 'constraint_end'] = f\"{time_to_change.year}-09-01\"\n",
    "\n",
    "                elif month == 7:  \n",
    "                    june_max = df[df['time'].dt.month == 6]['time'].max()\n",
    "                    august_max = df[df['time'].dt.month == 8]['time'].min()\n",
    "\n",
    "                    liste_data.loc[index_to_change, 'constraint_begin'] = june_max + pd.Timedelta(days=5)\n",
    "                    liste_data.loc[index_to_change, 'constraint_end'] = august_max - pd.Timedelta(days=5)\n",
    "\n",
    "    return liste_data\n",
    "\n",
    "liste_data = detect_conflit(liste_data)\n",
    "data_conflict = liste_data.loc[liste_data.to_change == 1].copy()\n",
    "data_clean = liste_data.loc[liste_data.to_change == 0].copy()\n",
    "if len(liste_data) != len(data_clean) + len(data_conflict) : print('-ERROR-')\n",
    "print('There is ', len(data_conflict), ' conflicts (', np.round(len(data_conflict)/len(liste_data)*100), '%).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_month_LR_with_constraints (name, year, period, constraint_begin, constraint_end, block):\n",
    "\n",
    "    os.chdir(\"/downscaling/HadGEM_driven_COSMO/\"+period +str(year))\n",
    "    fichiers_month = [fichier for fichier in os.listdir() if fichier.startswith(name)]\n",
    "    liste_data = []\n",
    "\n",
    "    for ind in range(len(fichiers_month)) :\n",
    "\n",
    "        data=xr.open_dataset(fichiers_month[ind])\n",
    "        \n",
    "        data = data.sel(rlon = slice(*lon_bnd), rlat = slice(*lat_bnd))\n",
    "        vars_to_keep = ['rlat', 'rlon', 'TOT_PR', 'time']  \n",
    "        data = data.drop_vars([var for var in data.variables if var not in vars_to_keep])\n",
    "        data = data.to_dataframe()\n",
    "        data= data.reset_index()\n",
    "        data = data.loc[(data.time >= constraint_begin) & (data.time <= constraint_end)]\n",
    "\n",
    "        data.rlat = round(data.rlat, 2)\n",
    "        data.rlon = round(data.rlon, 2)\n",
    "\n",
    "        data = pd.merge(data, grille, on = ['rlat', 'rlon'], how = 'left')\n",
    "        data = data.loc[data['block'].isin(block)]\n",
    "\n",
    "        data_time = data.time[0]\n",
    "        data = data.groupby(['block'])['TOT_PR'].mean().reset_index()\n",
    "        data['time'] = data_time\n",
    "        liste_data.append(data)\n",
    "\n",
    "    liste_data = pd.concat(liste_data, ignore_index = True)\n",
    "    liste_data = liste_data.reset_index() \n",
    "    \n",
    "    ind = liste_data.groupby(['block'])['TOT_PR'].idxmax()\n",
    "    liste_data = liste_data.loc[ind]\n",
    "\n",
    "    liste_data['year'] = year\n",
    "    liste_data['month'] = name[8:10]\n",
    "    liste_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return liste_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_local0 = liste_data.loc[liste_data.to_change == 1].copy()\n",
    "df_local0['constraint_end'] = pd.to_datetime(df_local0['constraint_end'])\n",
    "df_local0['constraint_begin'] = pd.to_datetime(df_local0['constraint_begin'])\n",
    "df_local0.reset_index(inplace = True)\n",
    "\n",
    "liste_data_new = []\n",
    "pb = []\n",
    "\n",
    "for index in tqdm.tqdm(df_local0.index) :\n",
    "       df_local = df_local0.loc[df_local0.index == index]\n",
    "       year = df_local0.loc[index, 'year']\n",
    "\n",
    "\n",
    "       mois = '0'+str(df_local0.loc[index, 'month'])[0]\n",
    "       name = 'lffd'+str(int(year)) + mois\n",
    "      \n",
    "       print(len(df_local))\n",
    "\n",
    "\n",
    "       df_result = get_max_month_LR_with_constraints (name, year, min(df_local.constraint_begin),\n",
    "                                                       max(df_local.constraint_end),\n",
    "                                                       list(df_local.block.unique()))\n",
    "       if not isinstance(df_result, pd.DataFrame): pb.append(index)\n",
    "       else :\n",
    "           df_local = df_local.drop(columns = ['TOT_PR', 'time'])\n",
    "\n",
    "\n",
    "           df_merge = pd.merge(df_local, df_result[['block', 'TOT_PR', 'time']], on = ['block'], how = 'left')\n",
    "           print('Warning :' , np.sum(df_merge.TOT_PR.isna()))\n",
    "\n",
    "\n",
    "           liste_data_new.append(df_merge.loc[(df_merge['time'] <= df_merge['constraint_end']) & (df_merge['time'] >= df_merge['constraint_begin'])])\n",
    "           df_local = df_merge.loc[(df_merge['time'] > df_merge['constraint_end']) | (df_merge['time'] < df_merge['constraint_begin'])]\n",
    "           if len(df_local)>0:\n",
    "               pb.append(index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.concat([liste_data.loc[liste_data.to_change == 0],\n",
    "          pd.concat(liste_data_new, ignore_index = True)],\n",
    "          ignore_index = True)\n",
    "\n",
    "\n",
    "os.chdir(\"/data/data_low_resolution\")\n",
    "d.to_csv('data2_summer_future_LR24_v1.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RainEx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
